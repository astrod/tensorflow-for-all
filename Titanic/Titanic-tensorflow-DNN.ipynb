{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv 파일을 읽어온다.\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "combine = [train, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "# 테스트에 사용할 컬럼들이 어떤 게 있는지 확인한다.\n",
    "print(train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 맨 위 다섯개를 확인하여, 데이터가 어떤 식으로 구현되는지 체크한다. 이름, 성별, Ticket, Cabin, Embarked는 숫자 데이터가 아니다.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# 정보를 확인한다. Age, Cabin, Embarked 는 데이터가 모자라다.\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 확인한다. 다음과 같은 사항을 확인할 수 있다.\n",
    "# 1. 생존은 카테고리 데이터이다 (0, 1)\n",
    "# 2. Pclass는 1,2,3 중 하나이다.\n",
    "# 3. 나이에서 제일 어린건 4개월, 제일 나이 많은건 80살\n",
    "# 4. 제일 비싸게 주고 탄 사람은 512달러\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Ball, Mrs. (Ada E Hall)</td>\n",
       "      <td>male</td>\n",
       "      <td>1601</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex Ticket    Cabin Embarked\n",
       "count                       891   891    891      204      889\n",
       "unique                      891     2    681      147        3\n",
       "top     Ball, Mrs. (Ada E Hall)  male   1601  B96 B98        S\n",
       "freq                          1   577      7        4      644"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 데이터를 확인하였다. 이제 데이터 사이의 연관관계를 찾고 싶다.\n",
    "먼저 Pclass와 Serviced 사이에 어떤 연관관계가 있는지 알고 싶다. 1등석에 탄 사람이 생존률이 높았을까?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived\n",
       "0       1  0.629630\n",
       "1       2  0.472826\n",
       "2       3  0.242363"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터로 미루어 보아, 1등석에 탄 사람이 생존률이 높았음을 알 수 있다. 성별와 생존률의 관계는 어떻게 될까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Survived\n",
       "0  female  0.742038\n",
       "1    male  0.188908"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여자가 남자보다 생존률이 유의미하게 높다. 성별과 생존률 사이에는 연관관계가 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.535885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.345395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Survived\n",
       "SibSp          \n",
       "1      0.535885\n",
       "2      0.464286\n",
       "0      0.345395\n",
       "3      0.250000\n",
       "4      0.166667\n",
       "5      0.000000\n",
       "8      0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['SibSp', 'Survived']].groupby(['SibSp']).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "형제의 수와 생존률도 연관이 있음을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parch</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.550847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.343658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parch  Survived\n",
       "3      3  0.600000\n",
       "1      1  0.550847\n",
       "2      2  0.500000\n",
       "0      0  0.343658\n",
       "5      5  0.200000\n",
       "4      4  0.000000\n",
       "6      6  0.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[[\"Parch\", \"Survived\"]].groupby([\"Parch\"], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FamilySize     Parch     SibSp  Survived\n",
      "0           1  0.000000  0.000000  0.303538\n",
      "1           2  0.236025  0.763975  0.552795\n",
      "2           3  1.127451  0.872549  0.578431\n",
      "3           4  1.655172  1.344828  0.724138\n",
      "4           5  1.866667  2.133333  0.200000\n",
      "5           6  2.181818  2.818182  0.136364\n",
      "6           7  2.750000  3.250000  0.333333\n",
      "7           8  2.666667  4.333333  0.000000\n",
      "8          11  2.000000  8.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "print (train[['Parch', 'SibSp', 'FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x10bdf37f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADQCAYAAABStPXYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bdf39b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = sns.FacetGrid(train, col='Survived')\n",
    "q.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   IsAlone  Survived\n",
      "0        0  0.505650\n",
      "1        1  0.303538\n"
     ]
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "print (train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 젊은 사람이 많이 죽었다.\n",
    "2. 어린 애들이 많이 살았다.\n",
    "3. 노인들은 다 살았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110152</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110413</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110465</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110564</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110813</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111240</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111320</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111361</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111369</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111426</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111427</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111428</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112050</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112052</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112053</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112058</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112059</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112277</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112379</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113028</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113043</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113050</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113051</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113055</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113056</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113059</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113501</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113503</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113505</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113509</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOTON/OQ 392082</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOTON/OQ 392086</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOTON/OQ 392089</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOTON/OQ 392090</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101269</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101273</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101274</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101275</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101280</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101285</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101286</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101288</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101289</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101292</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101293</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101294</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O2. 3101271</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O2. 3101279</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O2. 3101282</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O2. 3101283</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O2. 3101290</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SW/PP 751</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W./C. 14258</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W./C. 14263</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W./C. 6607</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W./C. 6608</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W./C. 6609</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W.E.P. 5734</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W/C 14208</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WE/P 5735</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Survived      \n",
       "                       mean count\n",
       "Ticket                           \n",
       "110152             1.000000     3\n",
       "110413             0.666667     3\n",
       "110465             0.000000     2\n",
       "110564             1.000000     1\n",
       "110813             1.000000     1\n",
       "111240             0.000000     1\n",
       "111320             0.000000     1\n",
       "111361             1.000000     2\n",
       "111369             1.000000     1\n",
       "111426             1.000000     1\n",
       "111427             1.000000     1\n",
       "111428             1.000000     1\n",
       "112050             0.000000     1\n",
       "112052             0.000000     1\n",
       "112053             1.000000     1\n",
       "112058             0.000000     1\n",
       "112059             0.000000     1\n",
       "112277             1.000000     1\n",
       "112379             0.000000     1\n",
       "113028             0.000000     1\n",
       "113043             0.000000     1\n",
       "113050             0.000000     1\n",
       "113051             0.000000     1\n",
       "113055             1.000000     1\n",
       "113056             0.000000     1\n",
       "113059             0.000000     1\n",
       "113501             0.000000     1\n",
       "113503             0.000000     1\n",
       "113505             1.000000     2\n",
       "113509             0.000000     1\n",
       "...                     ...   ...\n",
       "SOTON/OQ 392082    0.000000     1\n",
       "SOTON/OQ 392086    0.000000     1\n",
       "SOTON/OQ 392089    1.000000     1\n",
       "SOTON/OQ 392090    0.000000     1\n",
       "STON/O 2. 3101269  1.000000     1\n",
       "STON/O 2. 3101273  0.000000     1\n",
       "STON/O 2. 3101274  0.000000     1\n",
       "STON/O 2. 3101275  0.000000     1\n",
       "STON/O 2. 3101280  0.000000     1\n",
       "STON/O 2. 3101285  1.000000     1\n",
       "STON/O 2. 3101286  1.000000     1\n",
       "STON/O 2. 3101288  1.000000     1\n",
       "STON/O 2. 3101289  1.000000     1\n",
       "STON/O 2. 3101292  0.000000     1\n",
       "STON/O 2. 3101293  0.000000     1\n",
       "STON/O 2. 3101294  0.000000     1\n",
       "STON/O2. 3101271   0.000000     1\n",
       "STON/O2. 3101279   0.500000     2\n",
       "STON/O2. 3101282   1.000000     1\n",
       "STON/O2. 3101283   1.000000     1\n",
       "STON/O2. 3101290   0.000000     1\n",
       "SW/PP 751          1.000000     1\n",
       "W./C. 14258        1.000000     1\n",
       "W./C. 14263        0.000000     1\n",
       "W./C. 6607         0.000000     2\n",
       "W./C. 6608         0.000000     4\n",
       "W./C. 6609         0.000000     1\n",
       "W.E.P. 5734        0.000000     1\n",
       "W/C 14208          0.000000     1\n",
       "WE/P 5735          0.500000     2\n",
       "\n",
       "[681 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Ticket', 'Survived']].groupby(['Ticket'], as_index=False).agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x10bfa6198>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADQCAYAAABStPXYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bf8ff60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = sns.FacetGrid(train, col='Survived')\n",
    "q.map(plt.hist, 'Pclass', bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x10c27d2b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAHUCAYAAABMP5BeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAJAkqYMMAJIkddD/D/wqKm/BnRhXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bfa6a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = sns.FacetGrid(train, row='Embarked', col='Survived', size=2.2, aspect=1.6)\n",
    "grid.map(sns.barplot, 'Sex', 'Fare', alpha=.8, ci=None)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.553571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.389610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embarked  Survived\n",
       "0        C  0.553571\n",
       "1        Q  0.389610\n",
       "2        S  0.336957"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>59.954144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>27.079812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q</td>\n",
       "      <td>13.276030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embarked       Fare\n",
       "0        C  59.954144\n",
       "2        S  27.079812\n",
       "1        Q  13.276030"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Embarked', 'Fare']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Fare', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10c8320b8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdAAAAGwCAYAAAAZqTRaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c832780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('Feature correlations', y=1.05, size=12)\n",
    "sns.heatmap(train.corr(),linewidths=0.1,vmax=1.0, square=True, cmap=sns.color_palette(\"RdBu_r\",20), linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are dropping the attributes from both test and training datasets to maintain consistency\n",
    "train = train.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test = test.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salutation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countess</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex         female  male\n",
       "Salutation              \n",
       "Capt             0     1\n",
       "Col              0     2\n",
       "Countess         1     0\n",
       "Don              0     1\n",
       "Dr               1     6\n",
       "Jonkheer         0     1\n",
       "Lady             1     0\n",
       "Major            0     2\n",
       "Master           0    40\n",
       "Miss           182     0\n",
       "Mlle             2     0\n",
       "Mme              1     0\n",
       "Mr               0   517\n",
       "Mrs            125     0\n",
       "Ms               1     0\n",
       "Rev              0     6\n",
       "Sir              0     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Salutation'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "pd.crosstab(train['Salutation'], train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salutation</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Master</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miss</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr</td>\n",
       "      <td>0.156673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rare</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Salutation  Survived\n",
       "0     Master  0.575000\n",
       "1       Miss  0.702703\n",
       "2         Mr  0.156673\n",
       "3        Mrs  0.793651\n",
       "4       Rare  0.347826"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Salutation'] = dataset['Salutation'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Salutation'] = dataset['Salutation'].replace('Mlle', 'Miss')\n",
    "    dataset['Salutation'] = dataset['Salutation'].replace('Ms', 'Miss')\n",
    "    dataset['Salutation'] = dataset['Salutation'].replace('Mme', 'Mrs')\n",
    "    \n",
    "train[['Salutation', 'Survived']].groupby(['Salutation'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Salutation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch     Fare Embarked  FamilySize  IsAlone  Salutation  \n",
       "0      0   7.2500        S           2        0           1  \n",
       "1      0  71.2833        C           2        0           3  \n",
       "2      0   7.9250        S           1        1           2  \n",
       "3      0  53.1000        S           2        0           3  \n",
       "4      0   8.0500        S           1        1           1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Salutation_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Salutation'] = dataset['Salutation'].map(Salutation_mapping)\n",
    "    dataset['Salutation'] = dataset['Salutation'].fillna(0)\n",
    "    \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['Name', 'PassengerId'], axis=1)\n",
    "test = test.drop(['Name'], axis=1)\n",
    "combine = [train, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Salutation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  FamilySize  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S           2   \n",
       "1         1       1  female  38.0      1      0  71.2833        C           2   \n",
       "2         1       3  female  26.0      0      0   7.9250        S           1   \n",
       "3         1       1  female  35.0      1      0  53.1000        S           2   \n",
       "4         0       3    male  35.0      0      0   8.0500        S           1   \n",
       "\n",
       "   IsAlone  Salutation  \n",
       "0        0           1  \n",
       "1        0           3  \n",
       "2        1           2  \n",
       "3        0           3  \n",
       "4        1           1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "이제 문자로 된 것들을 숫자로 변화시키겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Salutation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare Embarked  FamilySize  \\\n",
       "0         0       3    0  22.0      1      0   7.2500        S           2   \n",
       "1         1       1    1  38.0      1      0  71.2833        C           2   \n",
       "2         1       3    1  26.0      0      0   7.9250        S           1   \n",
       "3         1       1    1  35.0      1      0  53.1000        S           2   \n",
       "4         0       3    0  35.0      0      0   8.0500        S           1   \n",
       "\n",
       "   IsAlone  Salutation  \n",
       "0        0           1  \n",
       "1        0           3  \n",
       "2        1           2  \n",
       "3        0           3  \n",
       "4        1           1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map({'female':1, 'male':0}).astype(int)\n",
    "    \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x10ce44b38>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAHUCAYAAABMP5BeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c74c400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')\n",
    "grid = sns.FacetGrid(train, row='Pclass', col='Sex', size=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "guess_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Salutation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  SibSp  Parch     Fare Embarked  FamilySize  \\\n",
       "0         0       3    0   22      1      0   7.2500        S           2   \n",
       "1         1       1    1   38      1      0  71.2833        C           2   \n",
       "2         1       3    1   26      0      0   7.9250        S           1   \n",
       "3         1       1    1   35      1      0  53.1000        S           2   \n",
       "4         0       3    0   35      0      0   8.0500        S           1   \n",
       "\n",
       "   IsAlone  Salutation  \n",
       "0        0           1  \n",
       "1        0           3  \n",
       "2        1           2  \n",
       "3        0           3  \n",
       "4        1           1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 티켓 같은사람 찾는 거 가능할거같음 ----\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            age_guess = guess.median()\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      "Survived      891 non-null int64\n",
      "Pclass        891 non-null int64\n",
      "Sex           891 non-null int64\n",
      "Age           891 non-null int64\n",
      "SibSp         891 non-null int64\n",
      "Parch         891 non-null int64\n",
      "Fare          891 non-null float64\n",
      "Embarked      889 non-null object\n",
      "FamilySize    891 non-null int64\n",
      "IsAlone       891 non-null int64\n",
      "Salutation    891 non-null int64\n",
      "dtypes: float64(1), int64(9), object(1)\n",
      "memory usage: 76.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>0.337374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>0.412037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(64.0, 80.0]</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AgeBand  Survived\n",
       "0  (-0.08, 16.0]  0.550000\n",
       "1   (16.0, 32.0]  0.337374\n",
       "2   (32.0, 48.0]  0.412037\n",
       "3   (48.0, 64.0]  0.434783\n",
       "4   (64.0, 80.0]  0.090909"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['AgeBand'] = pd.cut(train['Age'], 5)\n",
    "train[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Salutation</th>\n",
       "      <th>AgeBand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  SibSp  Parch     Fare Embarked  FamilySize  \\\n",
       "0         0       3    0    1      1      0   7.2500        S           2   \n",
       "1         1       1    1    2      1      0  71.2833        C           2   \n",
       "2         1       3    1    1      0      0   7.9250        S           1   \n",
       "3         1       1    1    2      1      0  53.1000        S           2   \n",
       "4         0       3    0    2      0      0   8.0500        S           1   \n",
       "\n",
       "   IsAlone  Salutation       AgeBand  \n",
       "0        0           1  (16.0, 32.0]  \n",
       "1        0           3  (32.0, 48.0]  \n",
       "2        1           2  (16.0, 32.0]  \n",
       "3        0           3  (32.0, 48.0]  \n",
       "4        1           1  (32.0, 48.0]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:    \n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Salutation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>811.000000</td>\n",
       "      <td>811.00000</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>811.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383477</td>\n",
       "      <td>2.38471</td>\n",
       "      <td>0.357583</td>\n",
       "      <td>1.143033</td>\n",
       "      <td>0.545006</td>\n",
       "      <td>0.392109</td>\n",
       "      <td>30.707038</td>\n",
       "      <td>1.937115</td>\n",
       "      <td>0.600493</td>\n",
       "      <td>1.697904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486533</td>\n",
       "      <td>0.80582</td>\n",
       "      <td>0.479584</td>\n",
       "      <td>0.607980</td>\n",
       "      <td>1.142397</td>\n",
       "      <td>0.817486</td>\n",
       "      <td>49.557496</td>\n",
       "      <td>1.662139</td>\n",
       "      <td>0.490099</td>\n",
       "      <td>0.978148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.412500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived     Pclass         Sex         Age       SibSp       Parch  \\\n",
       "count  811.000000  811.00000  811.000000  811.000000  811.000000  811.000000   \n",
       "mean     0.383477    2.38471    0.357583    1.143033    0.545006    0.392109   \n",
       "std      0.486533    0.80582    0.479584    0.607980    1.142397    0.817486   \n",
       "min      0.000000    1.00000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    2.00000    0.000000    1.000000    0.000000    0.000000   \n",
       "50%      0.000000    3.00000    0.000000    1.000000    0.000000    0.000000   \n",
       "75%      1.000000    3.00000    1.000000    2.000000    1.000000    0.000000   \n",
       "max      1.000000    3.00000    1.000000    2.000000    8.000000    6.000000   \n",
       "\n",
       "             Fare  FamilySize     IsAlone  Salutation  \n",
       "count  811.000000  811.000000  811.000000  811.000000  \n",
       "mean    30.707038    1.937115    0.600493    1.697904  \n",
       "std     49.557496    1.662139    0.490099    0.978148  \n",
       "min      0.000000    1.000000    0.000000    1.000000  \n",
       "25%      7.895800    1.000000    0.000000    1.000000  \n",
       "50%     13.000000    1.000000    1.000000    1.000000  \n",
       "75%     29.412500    2.000000    1.000000    2.000000  \n",
       "max    512.329200   11.000000    1.000000    5.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for dataset in combine :\n",
    "#    dataset.query('Age < 3')\n",
    "train.query('Age < 3').describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      595\n",
       "Pclass        595\n",
       "Sex           595\n",
       "Age           595\n",
       "SibSp         595\n",
       "Parch         595\n",
       "Fare          595\n",
       "Embarked      595\n",
       "FamilySize    595\n",
       "IsAlone       595\n",
       "Salutation    595\n",
       "AgeBand       595\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.query('Age < 2').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_port = train.Embarked.dropna().mode()[0]\n",
    "freq_port\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.553571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.389610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>0.339009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embarked  Survived\n",
       "0        C  0.553571\n",
       "1        Q  0.389610\n",
       "2        S  0.339009"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embark를 freq로 채우는 것은 좀 잘못 된 것 같다.. 차라리 drop하는게 낫지 않을까.\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'].fillna(freq_port, inplace=True)\n",
    "    \n",
    "train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Salutation</th>\n",
       "      <th>AgeBand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  SibSp  Parch     Fare  Embarked  FamilySize  \\\n",
       "0         0       3    0    1      1      0   7.2500         0           2   \n",
       "1         1       1    1    2      1      0  71.2833         1           2   \n",
       "2         1       3    1    1      0      0   7.9250         0           1   \n",
       "3         1       1    1    2      1      0  53.1000         0           2   \n",
       "4         0       3    0    2      0      0   8.0500         0           1   \n",
       "\n",
       "   IsAlone  Salutation       AgeBand  \n",
       "0        0           1  (16.0, 32.0]  \n",
       "1        0           3  (32.0, 48.0]  \n",
       "2        1           2  (16.0, 32.0]  \n",
       "3        0           3  (32.0, 48.0]  \n",
       "4        1           1  (32.0, 48.0]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Salutation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1044</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  FamilySize  \\\n",
       "152         1044       3    0    3      0      0   NaN         0           1   \n",
       "\n",
       "     IsAlone  Salutation  \n",
       "152        1           1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 빈 값이 뭔지 찾는 것 \n",
    "test.query('Fare != Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Salutation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex  Age  SibSp  Parch     Fare  Embarked  FamilySize  \\\n",
       "0          892       3    0    2      0      0   7.8292         2           1   \n",
       "1          893       3    1    2      1      0   7.0000         0           2   \n",
       "2          894       2    0    3      0      0   9.6875         2           1   \n",
       "3          895       3    0    1      0      0   8.6625         0           1   \n",
       "4          896       3    1    1      1      1  12.2875         0           3   \n",
       "\n",
       "   IsAlone  Salutation  \n",
       "0        1           1  \n",
       "1        0           3  \n",
       "2        1           1  \n",
       "3        1           1  \n",
       "4        0           3  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Fare'].fillna(test['Fare'].dropna().median(), inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FareBand</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-0.001, 8.662]</td>\n",
       "      <td>0.198052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(8.662, 26.0]</td>\n",
       "      <td>0.402778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(26.0, 512.329]</td>\n",
       "      <td>0.559322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FareBand  Survived\n",
       "0  (-0.001, 8.662]  0.198052\n",
       "1    (8.662, 26.0]  0.402778\n",
       "2  (26.0, 512.329]  0.559322"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qcut은 value의 비율로 나눈 것, cut은 category의 값으로 나눈 것 \n",
    "train['FareBand'] = pd.qcut(train['Fare'], 3)\n",
    "train[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age*Class  Age  Pclass\n",
       "0          3    1       3\n",
       "1          2    2       1\n",
       "2          3    1       3\n",
       "3          2    2       1\n",
       "4          6    2       3\n",
       "5          3    1       3\n",
       "6          3    3       1\n",
       "7          0    0       3\n",
       "8          3    1       3\n",
       "9          0    0       2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 의미 업음\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n",
    "\n",
    "train.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Salutation</th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  FamilySize  \\\n",
       "0         0       3    0    1      1      0     0         0           2   \n",
       "1         1       1    1    2      1      0     3         1           2   \n",
       "2         1       3    1    1      0      0     1         0           1   \n",
       "3         1       1    1    2      1      0     3         0           2   \n",
       "4         0       3    0    2      0      0     1         0           1   \n",
       "5         0       3    0    1      0      0     1         2           1   \n",
       "6         0       1    0    3      0      0     3         0           1   \n",
       "7         0       3    0    0      3      1     2         0           5   \n",
       "8         1       3    1    1      0      2     1         0           3   \n",
       "9         1       2    1    0      1      0     2         1           2   \n",
       "\n",
       "   IsAlone  Salutation        AgeBand  Age*Class  \n",
       "0        0           1   (16.0, 32.0]          3  \n",
       "1        0           3   (32.0, 48.0]          2  \n",
       "2        1           2   (16.0, 32.0]          3  \n",
       "3        0           3   (32.0, 48.0]          2  \n",
       "4        1           1   (32.0, 48.0]          6  \n",
       "5        1           1   (16.0, 32.0]          3  \n",
       "6        1           1   (48.0, 64.0]          3  \n",
       "7        0           4  (-0.08, 16.0]          0  \n",
       "8        0           3   (16.0, 32.0]          3  \n",
       "9        0           3  (-0.08, 16.0]          0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train = train.drop(['FareBand'], axis=1)\n",
    "combine = [train, test]\n",
    "    \n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Salutation</th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  FamilySize  \\\n",
       "0         0       3    0    1      1      0     0         0           2   \n",
       "1         1       1    1    2      1      0     3         1           2   \n",
       "2         1       3    1    1      0      0     1         0           1   \n",
       "3         1       1    1    2      1      0     3         0           2   \n",
       "4         0       3    0    2      0      0     1         0           1   \n",
       "5         0       3    0    1      0      0     1         2           1   \n",
       "6         0       1    0    3      0      0     3         0           1   \n",
       "7         0       3    0    0      3      1     2         0           5   \n",
       "8         1       3    1    1      0      2     1         0           3   \n",
       "9         1       2    1    0      1      0     2         1           2   \n",
       "\n",
       "   IsAlone  Salutation        AgeBand  Age*Class  \n",
       "0        0           1   (16.0, 32.0]          3  \n",
       "1        0           3   (32.0, 48.0]          2  \n",
       "2        1           2   (16.0, 32.0]          3  \n",
       "3        0           3   (32.0, 48.0]          2  \n",
       "4        1           1   (32.0, 48.0]          6  \n",
       "5        1           1   (16.0, 32.0]          3  \n",
       "6        1           1   (48.0, 64.0]          3  \n",
       "7        0           4  (-0.08, 16.0]          0  \n",
       "8        0           3   (16.0, 32.0]          3  \n",
       "9        0           3  (-0.08, 16.0]          0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Salutation</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  FamilySize  \\\n",
       "0           0       3    0    1      1      0     0         0           2   \n",
       "1           1       1    1    2      1      0     3         1           2   \n",
       "2           1       3    1    1      0      0     1         0           1   \n",
       "3           1       1    1    2      1      0     3         0           2   \n",
       "4           0       3    0    2      0      0     1         0           1   \n",
       "5           0       3    0    1      0      0     1         2           1   \n",
       "6           0       1    0    3      0      0     3         0           1   \n",
       "7           0       3    0    0      3      1     2         0           5   \n",
       "8           1       3    1    1      0      2     1         0           3   \n",
       "9           1       2    1    0      1      0     2         1           2   \n",
       "10          1       3    1    0      1      1     2         0           3   \n",
       "11          1       1    1    3      0      0     2         0           1   \n",
       "12          0       3    0    1      0      0     1         0           1   \n",
       "13          0       3    0    2      1      5     3         0           7   \n",
       "14          0       3    1    0      0      0     0         0           1   \n",
       "15          1       2    1    3      0      0     2         0           1   \n",
       "16          0       3    0    0      4      1     2         2           6   \n",
       "17          1       2    0    1      0      0     1         0           1   \n",
       "18          0       3    1    1      1      0     2         0           2   \n",
       "19          1       3    1    1      0      0     0         1           1   \n",
       "20          0       2    0    2      0      0     2         0           1   \n",
       "21          1       2    0    2      0      0     1         0           1   \n",
       "22          1       3    1    0      0      0     1         2           1   \n",
       "23          1       1    0    1      0      0     3         0           1   \n",
       "24          0       3    1    0      3      1     2         0           5   \n",
       "25          1       3    1    2      1      5     3         0           7   \n",
       "26          0       3    0    1      0      0     0         1           1   \n",
       "27          0       1    0    1      3      2     3         0           6   \n",
       "28          1       3    1    1      0      0     0         2           1   \n",
       "29          0       3    0    1      0      0     0         0           1   \n",
       "..        ...     ...  ...  ...    ...    ...   ...       ...         ...   \n",
       "861         0       2    0    1      1      0     1         0           2   \n",
       "862         1       1    1    2      0      0     2         0           1   \n",
       "863         0       3    1    1      8      2     3         0          11   \n",
       "864         0       2    0    1      0      0     1         0           1   \n",
       "865         1       2    1    2      0      0     1         0           1   \n",
       "866         1       2    1    1      1      0     1         1           2   \n",
       "867         0       1    0    1      0      0     3         0           1   \n",
       "868         0       3    0    1      0      0     1         0           1   \n",
       "869         1       3    0    0      1      1     1         0           3   \n",
       "870         0       3    0    1      0      0     0         0           1   \n",
       "871         1       1    1    2      1      1     3         0           3   \n",
       "872         0       1    0    2      0      0     0         0           1   \n",
       "873         0       3    0    2      0      0     1         0           1   \n",
       "874         1       2    1    1      1      0     2         1           2   \n",
       "875         1       3    1    0      0      0     0         1           1   \n",
       "876         0       3    0    1      0      0     1         0           1   \n",
       "877         0       3    0    1      0      0     0         0           1   \n",
       "878         0       3    0    1      0      0     0         0           1   \n",
       "879         1       1    1    3      0      1     3         1           2   \n",
       "880         1       2    1    1      0      1     2         0           2   \n",
       "881         0       3    0    2      0      0     0         0           1   \n",
       "882         0       3    1    1      0      0     1         0           1   \n",
       "883         0       2    0    1      0      0     1         0           1   \n",
       "884         0       3    0    1      0      0     0         0           1   \n",
       "885         0       3    1    2      0      5     2         2           6   \n",
       "886         0       2    0    1      0      0     1         0           1   \n",
       "887         1       1    1    1      0      0     2         0           1   \n",
       "888         0       3    1    1      1      2     2         0           4   \n",
       "889         1       1    0    1      0      0     2         1           1   \n",
       "890         0       3    0    1      0      0     0         2           1   \n",
       "\n",
       "     IsAlone  Salutation  Age*Class  \n",
       "0          0           1          3  \n",
       "1          0           3          2  \n",
       "2          1           2          3  \n",
       "3          0           3          2  \n",
       "4          1           1          6  \n",
       "5          1           1          3  \n",
       "6          1           1          3  \n",
       "7          0           4          0  \n",
       "8          0           3          3  \n",
       "9          0           3          0  \n",
       "10         0           2          0  \n",
       "11         1           2          3  \n",
       "12         1           1          3  \n",
       "13         0           1          6  \n",
       "14         1           2          0  \n",
       "15         1           3          6  \n",
       "16         0           4          0  \n",
       "17         1           1          2  \n",
       "18         0           3          3  \n",
       "19         1           3          3  \n",
       "20         1           1          4  \n",
       "21         1           1          4  \n",
       "22         1           2          0  \n",
       "23         1           1          1  \n",
       "24         0           2          0  \n",
       "25         0           3          6  \n",
       "26         1           1          3  \n",
       "27         0           1          1  \n",
       "28         1           2          3  \n",
       "29         1           1          3  \n",
       "..       ...         ...        ...  \n",
       "861        0           1          2  \n",
       "862        1           3          2  \n",
       "863        0           2          3  \n",
       "864        1           1          2  \n",
       "865        1           3          4  \n",
       "866        0           2          2  \n",
       "867        1           1          1  \n",
       "868        1           1          3  \n",
       "869        0           4          0  \n",
       "870        1           1          3  \n",
       "871        0           3          2  \n",
       "872        1           1          2  \n",
       "873        1           1          6  \n",
       "874        0           3          2  \n",
       "875        1           2          0  \n",
       "876        1           1          3  \n",
       "877        1           1          3  \n",
       "878        1           1          3  \n",
       "879        0           3          3  \n",
       "880        0           3          2  \n",
       "881        1           1          6  \n",
       "882        1           2          3  \n",
       "883        1           1          2  \n",
       "884        1           1          3  \n",
       "885        0           3          6  \n",
       "886        1           5          2  \n",
       "887        1           2          1  \n",
       "888        0           2          3  \n",
       "889        1           1          1  \n",
       "890        1           1          3  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(['AgeBand'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10d582b38>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAKhCAYAAAC1sKMTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns6wzbIwxxhhjyqz/B6EfefLs3MWsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d582ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Feature correlations', y=1.05, size=15)\n",
    "sns.heatmap(train.corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Salutation</th>\n",
       "      <th>AgeBand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  FamilySize  \\\n",
       "0           0       3    0    1      1      0     0         0           2   \n",
       "1           1       1    1    2      1      0     3         1           2   \n",
       "2           1       3    1    1      0      0     1         0           1   \n",
       "3           1       1    1    2      1      0     3         0           2   \n",
       "4           0       3    0    2      0      0     1         0           1   \n",
       "5           0       3    0    1      0      0     1         2           1   \n",
       "6           0       1    0    3      0      0     3         0           1   \n",
       "7           0       3    0    0      3      1     2         0           5   \n",
       "8           1       3    1    1      0      2     1         0           3   \n",
       "9           1       2    1    0      1      0     2         1           2   \n",
       "10          1       3    1    0      1      1     2         0           3   \n",
       "11          1       1    1    3      0      0     2         0           1   \n",
       "12          0       3    0    1      0      0     1         0           1   \n",
       "13          0       3    0    2      1      5     3         0           7   \n",
       "14          0       3    1    0      0      0     0         0           1   \n",
       "15          1       2    1    3      0      0     2         0           1   \n",
       "16          0       3    0    0      4      1     2         2           6   \n",
       "17          1       2    0    1      0      0     1         0           1   \n",
       "18          0       3    1    1      1      0     2         0           2   \n",
       "19          1       3    1    1      0      0     0         1           1   \n",
       "20          0       2    0    2      0      0     2         0           1   \n",
       "21          1       2    0    2      0      0     1         0           1   \n",
       "22          1       3    1    0      0      0     1         2           1   \n",
       "23          1       1    0    1      0      0     3         0           1   \n",
       "24          0       3    1    0      3      1     2         0           5   \n",
       "25          1       3    1    2      1      5     3         0           7   \n",
       "26          0       3    0    1      0      0     0         1           1   \n",
       "27          0       1    0    1      3      2     3         0           6   \n",
       "28          1       3    1    1      0      0     0         2           1   \n",
       "29          0       3    0    1      0      0     0         0           1   \n",
       "..        ...     ...  ...  ...    ...    ...   ...       ...         ...   \n",
       "861         0       2    0    1      1      0     1         0           2   \n",
       "862         1       1    1    2      0      0     2         0           1   \n",
       "863         0       3    1    1      8      2     3         0          11   \n",
       "864         0       2    0    1      0      0     1         0           1   \n",
       "865         1       2    1    2      0      0     1         0           1   \n",
       "866         1       2    1    1      1      0     1         1           2   \n",
       "867         0       1    0    1      0      0     3         0           1   \n",
       "868         0       3    0    1      0      0     1         0           1   \n",
       "869         1       3    0    0      1      1     1         0           3   \n",
       "870         0       3    0    1      0      0     0         0           1   \n",
       "871         1       1    1    2      1      1     3         0           3   \n",
       "872         0       1    0    2      0      0     0         0           1   \n",
       "873         0       3    0    2      0      0     1         0           1   \n",
       "874         1       2    1    1      1      0     2         1           2   \n",
       "875         1       3    1    0      0      0     0         1           1   \n",
       "876         0       3    0    1      0      0     1         0           1   \n",
       "877         0       3    0    1      0      0     0         0           1   \n",
       "878         0       3    0    1      0      0     0         0           1   \n",
       "879         1       1    1    3      0      1     3         1           2   \n",
       "880         1       2    1    1      0      1     2         0           2   \n",
       "881         0       3    0    2      0      0     0         0           1   \n",
       "882         0       3    1    1      0      0     1         0           1   \n",
       "883         0       2    0    1      0      0     1         0           1   \n",
       "884         0       3    0    1      0      0     0         0           1   \n",
       "885         0       3    1    2      0      5     2         2           6   \n",
       "886         0       2    0    1      0      0     1         0           1   \n",
       "887         1       1    1    1      0      0     2         0           1   \n",
       "888         0       3    1    1      1      2     2         0           4   \n",
       "889         1       1    0    1      0      0     2         1           1   \n",
       "890         0       3    0    1      0      0     0         2           1   \n",
       "\n",
       "     IsAlone  Salutation        AgeBand  \n",
       "0          0           1   (16.0, 32.0]  \n",
       "1          0           3   (32.0, 48.0]  \n",
       "2          1           2   (16.0, 32.0]  \n",
       "3          0           3   (32.0, 48.0]  \n",
       "4          1           1   (32.0, 48.0]  \n",
       "5          1           1   (16.0, 32.0]  \n",
       "6          1           1   (48.0, 64.0]  \n",
       "7          0           4  (-0.08, 16.0]  \n",
       "8          0           3   (16.0, 32.0]  \n",
       "9          0           3  (-0.08, 16.0]  \n",
       "10         0           2  (-0.08, 16.0]  \n",
       "11         1           2   (48.0, 64.0]  \n",
       "12         1           1   (16.0, 32.0]  \n",
       "13         0           1   (32.0, 48.0]  \n",
       "14         1           2  (-0.08, 16.0]  \n",
       "15         1           3   (48.0, 64.0]  \n",
       "16         0           4  (-0.08, 16.0]  \n",
       "17         1           1   (16.0, 32.0]  \n",
       "18         0           3   (16.0, 32.0]  \n",
       "19         1           3   (16.0, 32.0]  \n",
       "20         1           1   (32.0, 48.0]  \n",
       "21         1           1   (32.0, 48.0]  \n",
       "22         1           2  (-0.08, 16.0]  \n",
       "23         1           1   (16.0, 32.0]  \n",
       "24         0           2  (-0.08, 16.0]  \n",
       "25         0           3   (32.0, 48.0]  \n",
       "26         1           1   (16.0, 32.0]  \n",
       "27         0           1   (16.0, 32.0]  \n",
       "28         1           2   (16.0, 32.0]  \n",
       "29         1           1   (16.0, 32.0]  \n",
       "..       ...         ...            ...  \n",
       "861        0           1   (16.0, 32.0]  \n",
       "862        1           3   (32.0, 48.0]  \n",
       "863        0           2   (16.0, 32.0]  \n",
       "864        1           1   (16.0, 32.0]  \n",
       "865        1           3   (32.0, 48.0]  \n",
       "866        0           2   (16.0, 32.0]  \n",
       "867        1           1   (16.0, 32.0]  \n",
       "868        1           1   (16.0, 32.0]  \n",
       "869        0           4  (-0.08, 16.0]  \n",
       "870        1           1   (16.0, 32.0]  \n",
       "871        0           3   (32.0, 48.0]  \n",
       "872        1           1   (32.0, 48.0]  \n",
       "873        1           1   (32.0, 48.0]  \n",
       "874        0           3   (16.0, 32.0]  \n",
       "875        1           2  (-0.08, 16.0]  \n",
       "876        1           1   (16.0, 32.0]  \n",
       "877        1           1   (16.0, 32.0]  \n",
       "878        1           1   (16.0, 32.0]  \n",
       "879        0           3   (48.0, 64.0]  \n",
       "880        0           3   (16.0, 32.0]  \n",
       "881        1           1   (32.0, 48.0]  \n",
       "882        1           2   (16.0, 32.0]  \n",
       "883        1           1   (16.0, 32.0]  \n",
       "884        1           1   (16.0, 32.0]  \n",
       "885        0           3   (32.0, 48.0]  \n",
       "886        1           5   (16.0, 32.0]  \n",
       "887        1           2   (16.0, 32.0]  \n",
       "888        0           2   (16.0, 32.0]  \n",
       "889        1           1   (16.0, 32.0]  \n",
       "890        1           1   (16.0, 32.0]  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(['Age*Class'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['AgeBand', 'Age*Class'],axis =1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.drop(['Age*Class'],axis =1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x117fbcd68>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.793652, step = 1\n",
      "INFO:tensorflow:global_step/sec: 420.371\n",
      "INFO:tensorflow:loss = 0.438254, step = 101 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.361\n",
      "INFO:tensorflow:loss = 0.422598, step = 201 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.961\n",
      "INFO:tensorflow:loss = 0.405415, step = 301 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.877\n",
      "INFO:tensorflow:loss = 0.407232, step = 401 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.617\n",
      "INFO:tensorflow:loss = 0.401505, step = 501 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.025\n",
      "INFO:tensorflow:loss = 0.419217, step = 601 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.669\n",
      "INFO:tensorflow:loss = 0.391719, step = 701 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.01\n",
      "INFO:tensorflow:loss = 0.404266, step = 801 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.755\n",
      "INFO:tensorflow:loss = 0.401982, step = 901 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.051\n",
      "INFO:tensorflow:loss = 0.39544, step = 1001 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.027\n",
      "INFO:tensorflow:loss = 0.412347, step = 1101 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.05\n",
      "INFO:tensorflow:loss = 0.412507, step = 1201 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.872\n",
      "INFO:tensorflow:loss = 0.404325, step = 1301 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.165\n",
      "INFO:tensorflow:loss = 0.391335, step = 1401 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.816\n",
      "INFO:tensorflow:loss = 0.410644, step = 1501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.379\n",
      "INFO:tensorflow:loss = 0.397835, step = 1601 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.058\n",
      "INFO:tensorflow:loss = 0.393707, step = 1701 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.205\n",
      "INFO:tensorflow:loss = 0.398762, step = 1801 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.521\n",
      "INFO:tensorflow:loss = 0.403829, step = 1901 (0.224 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.403395.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-11:36:19\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-11:36:20\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.852974, accuracy/baseline_label_mean = 0.383838, accuracy/threshold_0.500000_mean = 0.852974, auc = 0.891618, auc_precision_recall = 0.882688, global_step = 2000, labels/actual_label_mean = 0.383838, labels/prediction_mean = 0.390868, loss = 0.369728, precision/positive_threshold_0.500000_mean = 0.880866, recall/positive_threshold_0.500000_mean = 0.71345\n",
      "-----------------------정확도: 0.852974\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def _titanic_data_input_fn():\n",
    "    targets = tf.contrib.learn.extract_pandas_data(train.iloc[:,[0]])\n",
    "    feature = tf.contrib.learn.extract_pandas_data(train.drop(['Survived'], axis =1))\n",
    "    return tf.constant(feature), tf.constant(targets)\n",
    "\n",
    "def DNN():\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=10)]\n",
    "\n",
    "  # Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                              hidden_units=[64, 32],\n",
    "                                              n_classes=2,\n",
    "                                              optimizer=tf.train.AdamOptimizer(\n",
    "                                                  learning_rate=0.1   \n",
    "                                              ),\n",
    "                                              dropout=0.1,\n",
    "                                              model_dir=\"./dnn_model\")\n",
    "    \n",
    "    \n",
    "    classifier.fit(input_fn=_titanic_data_input_fn, steps=2000)\n",
    " \n",
    "\n",
    "    accuracy_score = classifier.evaluate(input_fn=_titanic_data_input_fn, steps=1)[\"accuracy\"]\n",
    "    print('-----------------------정확도: {0:f}'.format(accuracy_score))\n",
    "\n",
    "    \n",
    "DNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.1 DROPOUT 0.1\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x119423f28>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.759405, step = 1\n",
      "INFO:tensorflow:global_step/sec: 413.535\n",
      "INFO:tensorflow:loss = 0.400461, step = 101 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.336\n",
      "INFO:tensorflow:loss = 0.348852, step = 201 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.927\n",
      "INFO:tensorflow:loss = 0.348582, step = 301 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.147\n",
      "INFO:tensorflow:loss = 0.338462, step = 401 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.107\n",
      "INFO:tensorflow:loss = 0.319244, step = 501 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.991\n",
      "INFO:tensorflow:loss = 0.340317, step = 601 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.094\n",
      "INFO:tensorflow:loss = 0.347733, step = 701 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.982\n",
      "INFO:tensorflow:loss = 0.33546, step = 801 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.201\n",
      "INFO:tensorflow:loss = 0.322481, step = 901 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.225\n",
      "INFO:tensorflow:loss = 0.344793, step = 1001 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.067\n",
      "INFO:tensorflow:loss = 0.345096, step = 1101 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.85\n",
      "INFO:tensorflow:loss = 0.309911, step = 1201 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.492\n",
      "INFO:tensorflow:loss = 0.317795, step = 1301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.71\n",
      "INFO:tensorflow:loss = 0.33084, step = 1401 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.594\n",
      "INFO:tensorflow:loss = 0.317433, step = 1501 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.257\n",
      "INFO:tensorflow:loss = 0.318621, step = 1601 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.822\n",
      "INFO:tensorflow:loss = 0.308659, step = 1701 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.922\n",
      "INFO:tensorflow:loss = 0.31202, step = 1801 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.25\n",
      "INFO:tensorflow:loss = 0.323802, step = 1901 (0.209 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.326243.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:50:14\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:50:14\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.803371, accuracy/baseline_label_mean = 0.359551, accuracy/threshold_0.500000_mean = 0.803371, auc = 0.83676, auc_precision_recall = 0.784563, global_step = 2000, labels/actual_label_mean = 0.359551, labels/prediction_mean = 0.380957, loss = 0.715563, precision/positive_threshold_0.500000_mean = 0.723077, recall/positive_threshold_0.500000_mean = 0.734375\n",
      "-----------------------정확도: 0.803371\n",
      "1 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.1 DROPOUT 0.1\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11a082438>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.747948, step = 1\n",
      "INFO:tensorflow:global_step/sec: 468.114\n",
      "INFO:tensorflow:loss = 0.417677, step = 101 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.93\n",
      "INFO:tensorflow:loss = 0.392877, step = 201 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.943\n",
      "INFO:tensorflow:loss = 0.388558, step = 301 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.628\n",
      "INFO:tensorflow:loss = 0.373721, step = 401 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.42\n",
      "INFO:tensorflow:loss = 0.381071, step = 501 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.391\n",
      "INFO:tensorflow:loss = 0.359467, step = 601 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.981\n",
      "INFO:tensorflow:loss = 0.361299, step = 701 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.221\n",
      "INFO:tensorflow:loss = 0.372874, step = 801 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.147\n",
      "INFO:tensorflow:loss = 0.363356, step = 901 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.52\n",
      "INFO:tensorflow:loss = 0.355832, step = 1001 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.192\n",
      "INFO:tensorflow:loss = 0.376497, step = 1101 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.714\n",
      "INFO:tensorflow:loss = 0.362931, step = 1201 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.097\n",
      "INFO:tensorflow:loss = 0.386254, step = 1301 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.45\n",
      "INFO:tensorflow:loss = 0.376701, step = 1401 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.302\n",
      "INFO:tensorflow:loss = 0.356013, step = 1501 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.745\n",
      "INFO:tensorflow:loss = 0.358405, step = 1601 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.885\n",
      "INFO:tensorflow:loss = 0.367897, step = 1701 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.323\n",
      "INFO:tensorflow:loss = 0.367908, step = 1801 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.356378, step = 1901 (0.213 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.348554.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:50:27\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:50:28\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.853933, accuracy/baseline_label_mean = 0.353933, accuracy/threshold_0.500000_mean = 0.853933, auc = 0.895652, auc_precision_recall = 0.873495, global_step = 2000, labels/actual_label_mean = 0.353933, labels/prediction_mean = 0.343691, loss = 0.397711, precision/positive_threshold_0.500000_mean = 0.893617, recall/positive_threshold_0.500000_mean = 0.666667\n",
      "-----------------------정확도: 0.853933\n",
      "2 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.1 DROPOUT 0.1\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1194235c0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.838787, step = 1\n",
      "INFO:tensorflow:global_step/sec: 474.895\n",
      "INFO:tensorflow:loss = 0.666127, step = 101 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.911\n",
      "INFO:tensorflow:loss = 0.666126, step = 201 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.818\n",
      "INFO:tensorflow:loss = 0.666127, step = 301 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.401\n",
      "INFO:tensorflow:loss = 0.666127, step = 401 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.833\n",
      "INFO:tensorflow:loss = 0.666127, step = 501 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.776\n",
      "INFO:tensorflow:loss = 0.666127, step = 601 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.952\n",
      "INFO:tensorflow:loss = 0.666127, step = 701 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.471\n",
      "INFO:tensorflow:loss = 0.666127, step = 801 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.986\n",
      "INFO:tensorflow:loss = 0.666127, step = 901 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.106\n",
      "INFO:tensorflow:loss = 0.666127, step = 1001 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.516\n",
      "INFO:tensorflow:loss = 0.666127, step = 1101 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.539\n",
      "INFO:tensorflow:loss = 0.666127, step = 1201 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.622\n",
      "INFO:tensorflow:loss = 0.666127, step = 1301 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 504.492\n",
      "INFO:tensorflow:loss = 0.666127, step = 1401 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.784\n",
      "INFO:tensorflow:loss = 0.666127, step = 1501 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.2\n",
      "INFO:tensorflow:loss = 0.666127, step = 1601 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.152\n",
      "INFO:tensorflow:loss = 0.666127, step = 1701 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.114\n",
      "INFO:tensorflow:loss = 0.666127, step = 1801 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.246\n",
      "INFO:tensorflow:loss = 0.666127, step = 1901 (0.201 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.666127.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:50:41\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:50:41\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.617977, accuracy/baseline_label_mean = 0.382022, accuracy/threshold_0.500000_mean = 0.617977, auc = 0.5, auc_precision_recall = 0.691011, global_step = 2000, labels/actual_label_mean = 0.382022, labels/prediction_mean = 0.384292, loss = 0.665056, precision/positive_threshold_0.500000_mean = 0.0, recall/positive_threshold_0.500000_mean = 0.0\n",
      "-----------------------정확도: 0.617977\n",
      "3 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.1 DROPOUT 0.1\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11a29a400>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.730191, step = 1\n",
      "INFO:tensorflow:global_step/sec: 387.403\n",
      "INFO:tensorflow:loss = 0.404236, step = 101 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.924\n",
      "INFO:tensorflow:loss = 0.407741, step = 201 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.132\n",
      "INFO:tensorflow:loss = 0.394734, step = 301 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.192\n",
      "INFO:tensorflow:loss = 0.403194, step = 401 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.568\n",
      "INFO:tensorflow:loss = 0.402024, step = 501 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.733\n",
      "INFO:tensorflow:loss = 0.398734, step = 601 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.839\n",
      "INFO:tensorflow:loss = 0.398158, step = 701 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.053\n",
      "INFO:tensorflow:loss = 0.38601, step = 801 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.373\n",
      "INFO:tensorflow:loss = 0.395552, step = 901 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.062\n",
      "INFO:tensorflow:loss = 0.382661, step = 1001 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.058\n",
      "INFO:tensorflow:loss = 0.384426, step = 1101 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.337\n",
      "INFO:tensorflow:loss = 0.401067, step = 1201 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.37\n",
      "INFO:tensorflow:loss = 0.383184, step = 1301 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.653\n",
      "INFO:tensorflow:loss = 0.378371, step = 1401 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.179\n",
      "INFO:tensorflow:loss = 0.39195, step = 1501 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.863\n",
      "INFO:tensorflow:loss = 0.397158, step = 1601 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.381\n",
      "INFO:tensorflow:loss = 0.387363, step = 1701 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.575\n",
      "INFO:tensorflow:loss = 0.3971, step = 1801 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.67\n",
      "INFO:tensorflow:loss = 0.39969, step = 1901 (0.201 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.377161.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:50:54\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:50:55\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.780899, accuracy/baseline_label_mean = 0.41573, accuracy/threshold_0.500000_mean = 0.780899, auc = 0.826014, auc_precision_recall = 0.796671, global_step = 2000, labels/actual_label_mean = 0.41573, labels/prediction_mean = 0.36442, loss = 0.528781, precision/positive_threshold_0.500000_mean = 0.843137, recall/positive_threshold_0.500000_mean = 0.581081\n",
      "-----------------------정확도: 0.780899\n",
      "4 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.1 DROPOUT 0.1\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1194232e8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.757281, step = 1\n",
      "INFO:tensorflow:global_step/sec: 477.575\n",
      "INFO:tensorflow:loss = 0.409093, step = 101 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.697\n",
      "INFO:tensorflow:loss = 0.404889, step = 201 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.482\n",
      "INFO:tensorflow:loss = 0.392158, step = 301 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.397\n",
      "INFO:tensorflow:loss = 0.386184, step = 401 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.307\n",
      "INFO:tensorflow:loss = 0.384714, step = 501 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.178\n",
      "INFO:tensorflow:loss = 0.40023, step = 601 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.253\n",
      "INFO:tensorflow:loss = 0.375703, step = 701 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.312\n",
      "INFO:tensorflow:loss = 0.402239, step = 801 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.422\n",
      "INFO:tensorflow:loss = 0.385255, step = 901 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.455\n",
      "INFO:tensorflow:loss = 0.387283, step = 1001 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.176\n",
      "INFO:tensorflow:loss = 0.378823, step = 1101 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.763\n",
      "INFO:tensorflow:loss = 0.389665, step = 1201 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.554\n",
      "INFO:tensorflow:loss = 0.412876, step = 1301 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.245\n",
      "INFO:tensorflow:loss = 0.418724, step = 1401 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.046\n",
      "INFO:tensorflow:loss = 0.403602, step = 1501 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.984\n",
      "INFO:tensorflow:loss = 0.384472, step = 1601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.196\n",
      "INFO:tensorflow:loss = 0.375444, step = 1701 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.823\n",
      "INFO:tensorflow:loss = 0.387764, step = 1801 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.28\n",
      "INFO:tensorflow:loss = 0.400575, step = 1901 (0.197 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.36708.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:51:08\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:51:08\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.803371, accuracy/baseline_label_mean = 0.410112, accuracy/threshold_0.500000_mean = 0.803371, auc = 0.875864, auc_precision_recall = 0.831136, global_step = 2000, labels/actual_label_mean = 0.410112, labels/prediction_mean = 0.422305, loss = 0.435597, precision/positive_threshold_0.500000_mean = 0.787879, recall/positive_threshold_0.500000_mean = 0.712329\n",
      "-----------------------정확도: 0.803371\n",
      "0 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.1 DROPOUT 0.4\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x119fc3a90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.806827, step = 1\n",
      "INFO:tensorflow:global_step/sec: 454.758\n",
      "INFO:tensorflow:loss = 0.454161, step = 101 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.361\n",
      "INFO:tensorflow:loss = 0.449203, step = 201 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.436\n",
      "INFO:tensorflow:loss = 0.446648, step = 301 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.08\n",
      "INFO:tensorflow:loss = 0.478323, step = 401 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.986\n",
      "INFO:tensorflow:loss = 0.435784, step = 501 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.226\n",
      "INFO:tensorflow:loss = 0.419739, step = 601 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.129\n",
      "INFO:tensorflow:loss = 0.446474, step = 701 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.363\n",
      "INFO:tensorflow:loss = 0.427609, step = 801 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.223\n",
      "INFO:tensorflow:loss = 0.428491, step = 901 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.621\n",
      "INFO:tensorflow:loss = 0.419202, step = 1001 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.875\n",
      "INFO:tensorflow:loss = 0.424887, step = 1101 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.198\n",
      "INFO:tensorflow:loss = 0.430223, step = 1201 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.545\n",
      "INFO:tensorflow:loss = 0.430283, step = 1301 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.033\n",
      "INFO:tensorflow:loss = 0.44778, step = 1401 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.589\n",
      "INFO:tensorflow:loss = 0.471182, step = 1501 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.78\n",
      "INFO:tensorflow:loss = 0.427375, step = 1601 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.729\n",
      "INFO:tensorflow:loss = 0.424107, step = 1701 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.111\n",
      "INFO:tensorflow:loss = 0.443352, step = 1801 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.386\n",
      "INFO:tensorflow:loss = 0.469354, step = 1901 (0.188 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.444692.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:51:21\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:51:22\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.797753, accuracy/baseline_label_mean = 0.359551, accuracy/threshold_0.500000_mean = 0.797753, auc = 0.805716, auc_precision_recall = 0.752653, global_step = 2000, labels/actual_label_mean = 0.359551, labels/prediction_mean = 0.38837, loss = 0.739912, precision/positive_threshold_0.500000_mean = 0.804348, recall/positive_threshold_0.500000_mean = 0.578125\n",
      "-----------------------정확도: 0.797753\n",
      "1 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.1 DROPOUT 0.4\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11895c470>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.745246, step = 1\n",
      "INFO:tensorflow:global_step/sec: 432.486\n",
      "INFO:tensorflow:loss = 0.499286, step = 101 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.876\n",
      "INFO:tensorflow:loss = 0.487643, step = 201 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.482\n",
      "INFO:tensorflow:loss = 0.496685, step = 301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.785\n",
      "INFO:tensorflow:loss = 0.506525, step = 401 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.794\n",
      "INFO:tensorflow:loss = 0.523495, step = 501 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.11\n",
      "INFO:tensorflow:loss = 0.502752, step = 601 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.919\n",
      "INFO:tensorflow:loss = 0.513254, step = 701 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.203\n",
      "INFO:tensorflow:loss = 0.503832, step = 801 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.124\n",
      "INFO:tensorflow:loss = 0.481186, step = 901 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.55\n",
      "INFO:tensorflow:loss = 0.491959, step = 1001 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.954\n",
      "INFO:tensorflow:loss = 0.499561, step = 1101 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.718\n",
      "INFO:tensorflow:loss = 0.527392, step = 1201 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.53\n",
      "INFO:tensorflow:loss = 0.487225, step = 1301 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.175\n",
      "INFO:tensorflow:loss = 0.507026, step = 1401 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.953\n",
      "INFO:tensorflow:loss = 0.497342, step = 1501 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.022\n",
      "INFO:tensorflow:loss = 0.504599, step = 1601 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.096\n",
      "INFO:tensorflow:loss = 0.506058, step = 1701 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.98\n",
      "INFO:tensorflow:loss = 0.498135, step = 1801 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.302\n",
      "INFO:tensorflow:loss = 0.519169, step = 1901 (0.220 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.491263.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:51:35\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:51:35\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.853933, accuracy/baseline_label_mean = 0.353933, accuracy/threshold_0.500000_mean = 0.853933, auc = 0.901518, auc_precision_recall = 0.880244, global_step = 2000, labels/actual_label_mean = 0.353933, labels/prediction_mean = 0.360119, loss = 0.393644, precision/positive_threshold_0.500000_mean = 0.893617, recall/positive_threshold_0.500000_mean = 0.666667\n",
      "-----------------------정확도: 0.853933\n",
      "2 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.1 DROPOUT 0.4\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11c0192e8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.702675, step = 1\n",
      "INFO:tensorflow:global_step/sec: 455.357\n",
      "INFO:tensorflow:loss = 0.493894, step = 101 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.797\n",
      "INFO:tensorflow:loss = 0.472423, step = 201 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.195\n",
      "INFO:tensorflow:loss = 0.447562, step = 301 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.658\n",
      "INFO:tensorflow:loss = 0.481454, step = 401 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.869\n",
      "INFO:tensorflow:loss = 0.471727, step = 501 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.446\n",
      "INFO:tensorflow:loss = 0.46794, step = 601 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.548\n",
      "INFO:tensorflow:loss = 0.500769, step = 701 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.771\n",
      "INFO:tensorflow:loss = 0.443241, step = 801 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.056\n",
      "INFO:tensorflow:loss = 0.475954, step = 901 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.665\n",
      "INFO:tensorflow:loss = 0.438534, step = 1001 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.113\n",
      "INFO:tensorflow:loss = 0.438237, step = 1101 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.35\n",
      "INFO:tensorflow:loss = 0.45593, step = 1201 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.315\n",
      "INFO:tensorflow:loss = 0.473377, step = 1301 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.615\n",
      "INFO:tensorflow:loss = 0.452331, step = 1401 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.213\n",
      "INFO:tensorflow:loss = 0.491662, step = 1501 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.156\n",
      "INFO:tensorflow:loss = 0.488054, step = 1601 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.49\n",
      "INFO:tensorflow:loss = 0.44307, step = 1701 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.93\n",
      "INFO:tensorflow:loss = 0.47168, step = 1801 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.431\n",
      "INFO:tensorflow:loss = 0.466743, step = 1901 (0.206 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.457541.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:51:49\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:51:49\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.825843, accuracy/baseline_label_mean = 0.382022, accuracy/threshold_0.500000_mean = 0.825843, auc = 0.853275, auc_precision_recall = 0.852192, global_step = 2000, labels/actual_label_mean = 0.382022, labels/prediction_mean = 0.39404, loss = 0.547842, precision/positive_threshold_0.500000_mean = 0.849057, recall/positive_threshold_0.500000_mean = 0.661765\n",
      "-----------------------정확도: 0.825843\n",
      "3 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.1 DROPOUT 0.4\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11846b208>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.837862, step = 1\n",
      "INFO:tensorflow:global_step/sec: 451.088\n",
      "INFO:tensorflow:loss = 0.493242, step = 101 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.123\n",
      "INFO:tensorflow:loss = 0.445195, step = 201 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.903\n",
      "INFO:tensorflow:loss = 0.456264, step = 301 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.983\n",
      "INFO:tensorflow:loss = 0.467278, step = 401 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.019\n",
      "INFO:tensorflow:loss = 0.442484, step = 501 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.265\n",
      "INFO:tensorflow:loss = 0.467395, step = 601 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.935\n",
      "INFO:tensorflow:loss = 0.448115, step = 701 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.496\n",
      "INFO:tensorflow:loss = 0.449963, step = 801 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.149\n",
      "INFO:tensorflow:loss = 0.462568, step = 901 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.109\n",
      "INFO:tensorflow:loss = 0.442387, step = 1001 (0.199 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 501.452\n",
      "INFO:tensorflow:loss = 0.432429, step = 1101 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.359\n",
      "INFO:tensorflow:loss = 0.433949, step = 1201 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.186\n",
      "INFO:tensorflow:loss = 0.447566, step = 1301 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.535\n",
      "INFO:tensorflow:loss = 0.445287, step = 1401 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.633\n",
      "INFO:tensorflow:loss = 0.471158, step = 1501 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.178\n",
      "INFO:tensorflow:loss = 0.442039, step = 1601 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.526\n",
      "INFO:tensorflow:loss = 0.449358, step = 1701 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.188\n",
      "INFO:tensorflow:loss = 0.410252, step = 1801 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 539.06\n",
      "INFO:tensorflow:loss = 0.433858, step = 1901 (0.185 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.440243.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:52:02\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:52:03\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.786517, accuracy/baseline_label_mean = 0.41573, accuracy/threshold_0.500000_mean = 0.786517, auc = 0.830301, auc_precision_recall = 0.817275, global_step = 2000, labels/actual_label_mean = 0.41573, labels/prediction_mean = 0.388605, loss = 0.711692, precision/positive_threshold_0.500000_mean = 0.78125, recall/positive_threshold_0.500000_mean = 0.675676\n",
      "-----------------------정확도: 0.786517\n",
      "4 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.1 DROPOUT 0.4\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11af6e278>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.904612, step = 1\n",
      "INFO:tensorflow:global_step/sec: 484.329\n",
      "INFO:tensorflow:loss = 0.54754, step = 101 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.849\n",
      "INFO:tensorflow:loss = 0.537769, step = 201 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.942\n",
      "INFO:tensorflow:loss = 0.576052, step = 301 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.011\n",
      "INFO:tensorflow:loss = 0.528812, step = 401 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.435\n",
      "INFO:tensorflow:loss = 0.533992, step = 501 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.097\n",
      "INFO:tensorflow:loss = 0.520021, step = 601 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.146\n",
      "INFO:tensorflow:loss = 0.541012, step = 701 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.774\n",
      "INFO:tensorflow:loss = 0.56232, step = 801 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.291\n",
      "INFO:tensorflow:loss = 0.531452, step = 901 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.796\n",
      "INFO:tensorflow:loss = 0.558212, step = 1001 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.044\n",
      "INFO:tensorflow:loss = 0.562718, step = 1101 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.217\n",
      "INFO:tensorflow:loss = 0.562178, step = 1201 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.186\n",
      "INFO:tensorflow:loss = 0.508639, step = 1301 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 504.739\n",
      "INFO:tensorflow:loss = 0.497964, step = 1401 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.339\n",
      "INFO:tensorflow:loss = 0.530552, step = 1501 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.383\n",
      "INFO:tensorflow:loss = 0.53924, step = 1601 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.245\n",
      "INFO:tensorflow:loss = 0.523095, step = 1701 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.927\n",
      "INFO:tensorflow:loss = 0.494668, step = 1801 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.643\n",
      "INFO:tensorflow:loss = 0.549717, step = 1901 (0.190 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.542385.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:52:14\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:52:15\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.797753, accuracy/baseline_label_mean = 0.410112, accuracy/threshold_0.500000_mean = 0.797753, auc = 0.864579, auc_precision_recall = 0.820059, global_step = 2000, labels/actual_label_mean = 0.410112, labels/prediction_mean = 0.387362, loss = 0.471591, precision/positive_threshold_0.500000_mean = 0.760563, recall/positive_threshold_0.500000_mean = 0.739726\n",
      "-----------------------정확도: 0.797753\n",
      "0 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.01 DROPOUT 0.1\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11af6e5f8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.732853, step = 1\n",
      "INFO:tensorflow:global_step/sec: 483.741\n",
      "INFO:tensorflow:loss = 0.334366, step = 101 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.153\n",
      "INFO:tensorflow:loss = 0.310009, step = 201 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.384\n",
      "INFO:tensorflow:loss = 0.282818, step = 301 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 539.77\n",
      "INFO:tensorflow:loss = 0.263491, step = 401 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.448\n",
      "INFO:tensorflow:loss = 0.272147, step = 501 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.449\n",
      "INFO:tensorflow:loss = 0.261778, step = 601 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.257\n",
      "INFO:tensorflow:loss = 0.255195, step = 701 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.726\n",
      "INFO:tensorflow:loss = 0.262515, step = 801 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.573\n",
      "INFO:tensorflow:loss = 0.248949, step = 901 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.017\n",
      "INFO:tensorflow:loss = 0.258308, step = 1001 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.402\n",
      "INFO:tensorflow:loss = 0.245894, step = 1101 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.879\n",
      "INFO:tensorflow:loss = 0.240946, step = 1201 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.401\n",
      "INFO:tensorflow:loss = 0.24873, step = 1301 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.299\n",
      "INFO:tensorflow:loss = 0.249605, step = 1401 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.307\n",
      "INFO:tensorflow:loss = 0.240603, step = 1501 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.937\n",
      "INFO:tensorflow:loss = 0.254887, step = 1601 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.144\n",
      "INFO:tensorflow:loss = 0.252269, step = 1701 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.026\n",
      "INFO:tensorflow:loss = 0.246375, step = 1801 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.59\n",
      "INFO:tensorflow:loss = 0.236148, step = 1901 (0.186 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.246008.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:52:27\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:52:27\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.792135, accuracy/baseline_label_mean = 0.359551, accuracy/threshold_0.500000_mean = 0.792135, auc = 0.824219, auc_precision_recall = 0.755599, global_step = 2000, labels/actual_label_mean = 0.359551, labels/prediction_mean = 0.395963, loss = 0.916134, precision/positive_threshold_0.500000_mean = 0.714286, recall/positive_threshold_0.500000_mean = 0.703125\n",
      "-----------------------정확도: 0.792135\n",
      "1 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.01 DROPOUT 0.1\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11af79f28>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.891023, step = 1\n",
      "INFO:tensorflow:global_step/sec: 444.231\n",
      "INFO:tensorflow:loss = 0.368969, step = 101 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.798\n",
      "INFO:tensorflow:loss = 0.323445, step = 201 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.012\n",
      "INFO:tensorflow:loss = 0.308548, step = 301 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.537\n",
      "INFO:tensorflow:loss = 0.297206, step = 401 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.927\n",
      "INFO:tensorflow:loss = 0.277789, step = 501 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.455\n",
      "INFO:tensorflow:loss = 0.274375, step = 601 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.114\n",
      "INFO:tensorflow:loss = 0.259845, step = 701 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.415\n",
      "INFO:tensorflow:loss = 0.271697, step = 801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.145\n",
      "INFO:tensorflow:loss = 0.259062, step = 901 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.003\n",
      "INFO:tensorflow:loss = 0.257092, step = 1001 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.198\n",
      "INFO:tensorflow:loss = 0.248564, step = 1101 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.059\n",
      "INFO:tensorflow:loss = 0.256242, step = 1201 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.176\n",
      "INFO:tensorflow:loss = 0.249415, step = 1301 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.731\n",
      "INFO:tensorflow:loss = 0.257529, step = 1401 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.871\n",
      "INFO:tensorflow:loss = 0.250965, step = 1501 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.323\n",
      "INFO:tensorflow:loss = 0.243996, step = 1601 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.458\n",
      "INFO:tensorflow:loss = 0.243072, step = 1701 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.994\n",
      "INFO:tensorflow:loss = 0.248002, step = 1801 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.351\n",
      "INFO:tensorflow:loss = 0.24794, step = 1901 (0.212 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.240929.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:52:40\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:52:41\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.825843, accuracy/baseline_label_mean = 0.353933, accuracy/threshold_0.500000_mean = 0.825843, auc = 0.798275, auc_precision_recall = 0.777155, global_step = 2000, labels/actual_label_mean = 0.353933, labels/prediction_mean = 0.332621, loss = 1.25423, precision/positive_threshold_0.500000_mean = 0.785714, recall/positive_threshold_0.500000_mean = 0.698413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------정확도: 0.825843\n",
      "2 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.01 DROPOUT 0.1\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1191a2828>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.72342, step = 1\n",
      "INFO:tensorflow:global_step/sec: 425.141\n",
      "INFO:tensorflow:loss = 0.369202, step = 101 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.027\n",
      "INFO:tensorflow:loss = 0.317354, step = 201 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.013\n",
      "INFO:tensorflow:loss = 0.29485, step = 301 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.816\n",
      "INFO:tensorflow:loss = 0.296216, step = 401 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.189\n",
      "INFO:tensorflow:loss = 0.294401, step = 501 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.539\n",
      "INFO:tensorflow:loss = 0.257273, step = 601 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.759\n",
      "INFO:tensorflow:loss = 0.262674, step = 701 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 508.22\n",
      "INFO:tensorflow:loss = 0.272905, step = 801 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.558\n",
      "INFO:tensorflow:loss = 0.260177, step = 901 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.352\n",
      "INFO:tensorflow:loss = 0.260267, step = 1001 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.472\n",
      "INFO:tensorflow:loss = 0.252003, step = 1101 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.78\n",
      "INFO:tensorflow:loss = 0.253183, step = 1201 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.092\n",
      "INFO:tensorflow:loss = 0.251609, step = 1301 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.465\n",
      "INFO:tensorflow:loss = 0.254846, step = 1401 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.445\n",
      "INFO:tensorflow:loss = 0.253515, step = 1501 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.302\n",
      "INFO:tensorflow:loss = 0.243183, step = 1601 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.142\n",
      "INFO:tensorflow:loss = 0.251456, step = 1701 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.764\n",
      "INFO:tensorflow:loss = 0.243784, step = 1801 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.174\n",
      "INFO:tensorflow:loss = 0.270895, step = 1901 (0.202 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.241585.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:52:54\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:52:54\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.803371, accuracy/baseline_label_mean = 0.382022, accuracy/threshold_0.500000_mean = 0.803371, auc = 0.803342, auc_precision_recall = 0.785199, global_step = 2000, labels/actual_label_mean = 0.382022, labels/prediction_mean = 0.395438, loss = 1.19338, precision/positive_threshold_0.500000_mean = 0.761905, recall/positive_threshold_0.500000_mean = 0.705882\n",
      "-----------------------정확도: 0.803371\n",
      "3 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.01 DROPOUT 0.1\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11bb4a5f8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.832262, step = 1\n",
      "INFO:tensorflow:global_step/sec: 416.489\n",
      "INFO:tensorflow:loss = 0.352509, step = 101 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.324\n",
      "INFO:tensorflow:loss = 0.318198, step = 201 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.887\n",
      "INFO:tensorflow:loss = 0.291148, step = 301 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.146\n",
      "INFO:tensorflow:loss = 0.277051, step = 401 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.843\n",
      "INFO:tensorflow:loss = 0.271847, step = 501 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.488\n",
      "INFO:tensorflow:loss = 0.266129, step = 601 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.835\n",
      "INFO:tensorflow:loss = 0.252789, step = 701 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.313\n",
      "INFO:tensorflow:loss = 0.259123, step = 801 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.607\n",
      "INFO:tensorflow:loss = 0.257917, step = 901 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.947\n",
      "INFO:tensorflow:loss = 0.251682, step = 1001 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.064\n",
      "INFO:tensorflow:loss = 0.245934, step = 1101 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.714\n",
      "INFO:tensorflow:loss = 0.24451, step = 1201 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.633\n",
      "INFO:tensorflow:loss = 0.245602, step = 1301 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.655\n",
      "INFO:tensorflow:loss = 0.259817, step = 1401 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.615\n",
      "INFO:tensorflow:loss = 0.250979, step = 1501 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.62\n",
      "INFO:tensorflow:loss = 0.245146, step = 1601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.486\n",
      "INFO:tensorflow:loss = 0.246842, step = 1701 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.195\n",
      "INFO:tensorflow:loss = 0.238919, step = 1801 (0.206 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 463.304\n",
      "INFO:tensorflow:loss = 0.22912, step = 1901 (0.216 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.234411.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:53:08\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:53:08\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.775281, accuracy/baseline_label_mean = 0.41573, accuracy/threshold_0.500000_mean = 0.775281, auc = 0.803664, auc_precision_recall = 0.794881, global_step = 2000, labels/actual_label_mean = 0.41573, labels/prediction_mean = 0.390067, loss = 1.73999, precision/positive_threshold_0.500000_mean = 0.765625, recall/positive_threshold_0.500000_mean = 0.662162\n",
      "-----------------------정확도: 0.775281\n",
      "4 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.01 DROPOUT 0.1\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11c878e80>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.763314, step = 1\n",
      "INFO:tensorflow:global_step/sec: 441.86\n",
      "INFO:tensorflow:loss = 0.361116, step = 101 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.975\n",
      "INFO:tensorflow:loss = 0.325643, step = 201 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.807\n",
      "INFO:tensorflow:loss = 0.286408, step = 301 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 494\n",
      "INFO:tensorflow:loss = 0.29721, step = 401 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.466\n",
      "INFO:tensorflow:loss = 0.276932, step = 501 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.626\n",
      "INFO:tensorflow:loss = 0.278235, step = 601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.508\n",
      "INFO:tensorflow:loss = 0.255091, step = 701 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.597\n",
      "INFO:tensorflow:loss = 0.266233, step = 801 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.246\n",
      "INFO:tensorflow:loss = 0.256612, step = 901 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.347\n",
      "INFO:tensorflow:loss = 0.268171, step = 1001 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.732\n",
      "INFO:tensorflow:loss = 0.246347, step = 1101 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.203\n",
      "INFO:tensorflow:loss = 0.253123, step = 1201 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.768\n",
      "INFO:tensorflow:loss = 0.24316, step = 1301 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.697\n",
      "INFO:tensorflow:loss = 0.267261, step = 1401 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.363\n",
      "INFO:tensorflow:loss = 0.248501, step = 1501 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.572\n",
      "INFO:tensorflow:loss = 0.242243, step = 1601 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.517\n",
      "INFO:tensorflow:loss = 0.252412, step = 1701 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.471\n",
      "INFO:tensorflow:loss = 0.244012, step = 1801 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.189\n",
      "INFO:tensorflow:loss = 0.253607, step = 1901 (0.202 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.249472.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:53:21\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:53:22\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.797753, accuracy/baseline_label_mean = 0.410112, accuracy/threshold_0.500000_mean = 0.797753, auc = 0.820157, auc_precision_recall = 0.780079, global_step = 2000, labels/actual_label_mean = 0.410112, labels/prediction_mean = 0.438147, loss = 0.911871, precision/positive_threshold_0.500000_mean = 0.746667, recall/positive_threshold_0.500000_mean = 0.767123\n",
      "-----------------------정확도: 0.797753\n",
      "0 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.01 DROPOUT 0.4\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11833d470>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.74836, step = 1\n",
      "INFO:tensorflow:global_step/sec: 397.227\n",
      "INFO:tensorflow:loss = 0.398054, step = 101 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 508.68\n",
      "INFO:tensorflow:loss = 0.369017, step = 201 (0.196 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 425.57\n",
      "INFO:tensorflow:loss = 0.359849, step = 301 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.948\n",
      "INFO:tensorflow:loss = 0.33481, step = 401 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.09\n",
      "INFO:tensorflow:loss = 0.319108, step = 501 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.567\n",
      "INFO:tensorflow:loss = 0.320597, step = 601 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.429\n",
      "INFO:tensorflow:loss = 0.299557, step = 701 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.849\n",
      "INFO:tensorflow:loss = 0.304938, step = 801 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.715\n",
      "INFO:tensorflow:loss = 0.309711, step = 901 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 508.187\n",
      "INFO:tensorflow:loss = 0.30494, step = 1001 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.533\n",
      "INFO:tensorflow:loss = 0.298488, step = 1101 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.922\n",
      "INFO:tensorflow:loss = 0.30152, step = 1201 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.865\n",
      "INFO:tensorflow:loss = 0.299714, step = 1301 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.905\n",
      "INFO:tensorflow:loss = 0.298316, step = 1401 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.959\n",
      "INFO:tensorflow:loss = 0.312374, step = 1501 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.785\n",
      "INFO:tensorflow:loss = 0.297989, step = 1601 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.956\n",
      "INFO:tensorflow:loss = 0.297375, step = 1701 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.199\n",
      "INFO:tensorflow:loss = 0.295776, step = 1801 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.636\n",
      "INFO:tensorflow:loss = 0.288819, step = 1901 (0.209 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.313284.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:53:35\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:53:35\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.792135, accuracy/baseline_label_mean = 0.359551, accuracy/threshold_0.500000_mean = 0.792135, auc = 0.812637, auc_precision_recall = 0.762605, global_step = 2000, labels/actual_label_mean = 0.359551, labels/prediction_mean = 0.364177, loss = 1.29052, precision/positive_threshold_0.500000_mean = 0.754717, recall/positive_threshold_0.500000_mean = 0.625\n",
      "-----------------------정확도: 0.792135\n",
      "1 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.01 DROPOUT 0.4\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1190b2b38>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.810701, step = 1\n",
      "INFO:tensorflow:global_step/sec: 476.333\n",
      "INFO:tensorflow:loss = 0.402049, step = 101 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.67\n",
      "INFO:tensorflow:loss = 0.380641, step = 201 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.281\n",
      "INFO:tensorflow:loss = 0.354064, step = 301 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.241\n",
      "INFO:tensorflow:loss = 0.350367, step = 401 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.126\n",
      "INFO:tensorflow:loss = 0.344927, step = 501 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.628\n",
      "INFO:tensorflow:loss = 0.332468, step = 601 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.559\n",
      "INFO:tensorflow:loss = 0.332505, step = 701 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 504.182\n",
      "INFO:tensorflow:loss = 0.34482, step = 801 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.954\n",
      "INFO:tensorflow:loss = 0.324835, step = 901 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.323\n",
      "INFO:tensorflow:loss = 0.328221, step = 1001 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.011\n",
      "INFO:tensorflow:loss = 0.337256, step = 1101 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.595\n",
      "INFO:tensorflow:loss = 0.312176, step = 1201 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.246\n",
      "INFO:tensorflow:loss = 0.316524, step = 1301 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.235\n",
      "INFO:tensorflow:loss = 0.32983, step = 1401 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.759\n",
      "INFO:tensorflow:loss = 0.322713, step = 1501 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.345\n",
      "INFO:tensorflow:loss = 0.307601, step = 1601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.048\n",
      "INFO:tensorflow:loss = 0.329418, step = 1701 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.331\n",
      "INFO:tensorflow:loss = 0.324593, step = 1801 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.869\n",
      "INFO:tensorflow:loss = 0.315228, step = 1901 (0.208 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.306219.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:53:48\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:53:49\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.831461, accuracy/baseline_label_mean = 0.353933, accuracy/threshold_0.500000_mean = 0.831461, auc = 0.816149, auc_precision_recall = 0.807403, global_step = 2000, labels/actual_label_mean = 0.353933, labels/prediction_mean = 0.337254, loss = 1.18258, precision/positive_threshold_0.500000_mean = 0.811321, recall/positive_threshold_0.500000_mean = 0.68254\n",
      "-----------------------정확도: 0.831461\n",
      "2 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.01 DROPOUT 0.4\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11a4fc128>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.801394, step = 1\n",
      "INFO:tensorflow:global_step/sec: 475.631\n",
      "INFO:tensorflow:loss = 0.393623, step = 101 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.847\n",
      "INFO:tensorflow:loss = 0.3568, step = 201 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.565\n",
      "INFO:tensorflow:loss = 0.360202, step = 301 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.109\n",
      "INFO:tensorflow:loss = 0.352851, step = 401 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.184\n",
      "INFO:tensorflow:loss = 0.32557, step = 501 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.38\n",
      "INFO:tensorflow:loss = 0.334668, step = 601 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.32\n",
      "INFO:tensorflow:loss = 0.330125, step = 701 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.927\n",
      "INFO:tensorflow:loss = 0.336777, step = 801 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.356\n",
      "INFO:tensorflow:loss = 0.337103, step = 901 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.129\n",
      "INFO:tensorflow:loss = 0.334631, step = 1001 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.765\n",
      "INFO:tensorflow:loss = 0.317103, step = 1101 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.103\n",
      "INFO:tensorflow:loss = 0.332628, step = 1201 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.048\n",
      "INFO:tensorflow:loss = 0.330189, step = 1301 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.063\n",
      "INFO:tensorflow:loss = 0.31042, step = 1401 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.962\n",
      "INFO:tensorflow:loss = 0.309483, step = 1501 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.793\n",
      "INFO:tensorflow:loss = 0.327642, step = 1601 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 504.9\n",
      "INFO:tensorflow:loss = 0.302064, step = 1701 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.654\n",
      "INFO:tensorflow:loss = 0.31197, step = 1801 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.434\n",
      "INFO:tensorflow:loss = 0.310584, step = 1901 (0.227 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.324879.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:54:02\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:54:02\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.814607, accuracy/baseline_label_mean = 0.382022, accuracy/threshold_0.500000_mean = 0.814607, auc = 0.841444, auc_precision_recall = 0.833893, global_step = 2000, labels/actual_label_mean = 0.382022, labels/prediction_mean = 0.407889, loss = 0.801086, precision/positive_threshold_0.500000_mean = 0.761194, recall/positive_threshold_0.500000_mean = 0.75\n",
      "-----------------------정확도: 0.814607\n",
      "3 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.01 DROPOUT 0.4\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11946d828>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.723219, step = 1\n",
      "INFO:tensorflow:global_step/sec: 398.804\n",
      "INFO:tensorflow:loss = 0.383767, step = 101 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.564\n",
      "INFO:tensorflow:loss = 0.337568, step = 201 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.647\n",
      "INFO:tensorflow:loss = 0.328643, step = 301 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.894\n",
      "INFO:tensorflow:loss = 0.320077, step = 401 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.58\n",
      "INFO:tensorflow:loss = 0.318364, step = 501 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.78\n",
      "INFO:tensorflow:loss = 0.317651, step = 601 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.799\n",
      "INFO:tensorflow:loss = 0.311547, step = 701 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.059\n",
      "INFO:tensorflow:loss = 0.307487, step = 801 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.023\n",
      "INFO:tensorflow:loss = 0.308538, step = 901 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.84\n",
      "INFO:tensorflow:loss = 0.311285, step = 1001 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.567\n",
      "INFO:tensorflow:loss = 0.298923, step = 1101 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.779\n",
      "INFO:tensorflow:loss = 0.302511, step = 1201 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.09\n",
      "INFO:tensorflow:loss = 0.31139, step = 1301 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.538\n",
      "INFO:tensorflow:loss = 0.302067, step = 1401 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.781\n",
      "INFO:tensorflow:loss = 0.289674, step = 1501 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.511\n",
      "INFO:tensorflow:loss = 0.297105, step = 1601 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.616\n",
      "INFO:tensorflow:loss = 0.306635, step = 1701 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.495\n",
      "INFO:tensorflow:loss = 0.296956, step = 1801 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.257\n",
      "INFO:tensorflow:loss = 0.306568, step = 1901 (0.211 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.311793.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:54:15\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:54:16\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.775281, accuracy/baseline_label_mean = 0.41573, accuracy/threshold_0.500000_mean = 0.775281, auc = 0.817503, auc_precision_recall = 0.80443, global_step = 2000, labels/actual_label_mean = 0.41573, labels/prediction_mean = 0.389004, loss = 2.03814, precision/positive_threshold_0.500000_mean = 0.814815, recall/positive_threshold_0.500000_mean = 0.594595\n",
      "-----------------------정확도: 0.775281\n",
      "4 번째 루프. testSize 178 trainSize 713\n",
      "학습률 0.01 DROPOUT 0.4\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1186f05f8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.820685, step = 1\n",
      "INFO:tensorflow:global_step/sec: 480.922\n",
      "INFO:tensorflow:loss = 0.397294, step = 101 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.535\n",
      "INFO:tensorflow:loss = 0.373279, step = 201 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.557\n",
      "INFO:tensorflow:loss = 0.349497, step = 301 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.494\n",
      "INFO:tensorflow:loss = 0.332626, step = 401 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.554\n",
      "INFO:tensorflow:loss = 0.316765, step = 501 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.909\n",
      "INFO:tensorflow:loss = 0.334675, step = 601 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.16\n",
      "INFO:tensorflow:loss = 0.3205, step = 701 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.588\n",
      "INFO:tensorflow:loss = 0.346562, step = 801 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.054\n",
      "INFO:tensorflow:loss = 0.315027, step = 901 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.167\n",
      "INFO:tensorflow:loss = 0.30987, step = 1001 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.687\n",
      "INFO:tensorflow:loss = 0.324524, step = 1101 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.482\n",
      "INFO:tensorflow:loss = 0.315108, step = 1201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.791\n",
      "INFO:tensorflow:loss = 0.310963, step = 1301 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.405\n",
      "INFO:tensorflow:loss = 0.323263, step = 1401 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.447\n",
      "INFO:tensorflow:loss = 0.313947, step = 1501 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.022\n",
      "INFO:tensorflow:loss = 0.331392, step = 1601 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.187\n",
      "INFO:tensorflow:loss = 0.312776, step = 1701 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.22\n",
      "INFO:tensorflow:loss = 0.343302, step = 1801 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.938\n",
      "INFO:tensorflow:loss = 0.308425, step = 1901 (0.195 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.320262.\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-12:54:29\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-12:54:29\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.803371, accuracy/baseline_label_mean = 0.410112, accuracy/threshold_0.500000_mean = 0.803371, auc = 0.85362, auc_precision_recall = 0.816153, global_step = 2000, labels/actual_label_mean = 0.410112, labels/prediction_mean = 0.422785, loss = 0.603412, precision/positive_threshold_0.500000_mean = 0.779412, recall/positive_threshold_0.500000_mean = 0.726027\n",
      "-----------------------정확도: 0.803371\n",
      "정확도: 0.803371\n",
      "정확도: 0.853933\n",
      "정확도: 0.617977\n",
      "정확도: 0.780899\n",
      "정확도: 0.803371\n",
      "정확도: 0.797753\n",
      "정확도: 0.853933\n",
      "정확도: 0.825843\n",
      "정확도: 0.786517\n",
      "정확도: 0.797753\n",
      "정확도: 0.792135\n",
      "정확도: 0.825843\n",
      "정확도: 0.803371\n",
      "정확도: 0.775281\n",
      "정확도: 0.797753\n",
      "정확도: 0.792135\n",
      "정확도: 0.831461\n",
      "정확도: 0.814607\n",
      "정확도: 0.775281\n",
      "정확도: 0.803371\n",
      "----정확도 평균: 3.186517\n"
     ]
    }
   ],
   "source": [
    "# 테스트, 트레인 데이터를 2:8 비율로 나누어 테스트. 5번 돌린 후 정확도의 평균을 취한다.\n",
    "# 대략 81~82퍼 근방이 나옴\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "def _titanic_data_input_fn(data):        \n",
    "    targets = tf.contrib.learn.extract_pandas_data(data.iloc[:,[0]])\n",
    "    feature = tf.contrib.learn.extract_pandas_data(data.drop(['Survived'], axis =1))\n",
    "    return tf.constant(feature), tf.constant(targets)\n",
    "\n",
    "def DNN(trainData, testData, learning_rate, dropout):\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=10)]\n",
    "\n",
    "  # Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                              hidden_units=[64, 32],\n",
    "                                              n_classes=2,\n",
    "                                              optimizer=tf.train.AdamOptimizer(\n",
    "                                                  learning_rate=learning_rate  # 0.1 0.01 0.001\n",
    "                                              ),\n",
    "                                              dropout=dropout, # 0.1 0.2 0.3 \n",
    "                                              model_dir=\"./dnn_model\")\n",
    "    \n",
    "    \n",
    "    classifier.fit(input_fn=lambda: _titanic_data_input_fn(trainData), steps=2000)\n",
    " \n",
    "    accuracy_score = classifier.evaluate(input_fn=lambda: _titanic_data_input_fn(testData), steps=1)[\"accuracy\"]\n",
    "    print('-----------------------정확도: {0:f}'.format(accuracy_score))\n",
    "    accuracyList.append(accuracy_score)\n",
    "    \n",
    "        \n",
    "shuffledTrain = train.sample(frac=1)\n",
    "accuracyList = []\n",
    "chunkSize = 178\n",
    "\n",
    "learningRateList = [0.1, 0.01]\n",
    "dropoutList = [0.1, 0.4]\n",
    "for i in range(len(learningRateList)):\n",
    "    for j in range(len(dropoutList)):\n",
    "        for k in range(5):    \n",
    "            testData = shuffledTrain[k * chunkSize : chunkSize * (k + 1)]\n",
    "            trainData = shuffledTrain.drop(testData.index)\n",
    "            print(k, '번째 루프. testSize', len(testData), 'trainSize', len(trainData))\n",
    "            print('학습률', learningRateList[i], 'DROPOUT',  dropoutList[j])\n",
    "            DNN(trainData, testData, learningRateList[i], dropoutList[j])\n",
    "            shutil.rmtree(\"./dnn_model\")\n",
    "\n",
    "accuracy = 0\n",
    "for accuracyTarget in accuracyList:\n",
    "    print(\"정확도:\", accuracyTarget)\n",
    "    accuracy += accuracyTarget\n",
    "print('----정확도 평균: {0:f}'.format(accuracy/5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x117bc3e10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './dnn_model'}\n",
      "WARNING:tensorflow:From /Users/Naver/git/ml/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.684153, step = 1\n",
      "INFO:tensorflow:global_step/sec: 429.712\n",
      "INFO:tensorflow:loss = 0.361408, step = 101 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.016\n",
      "INFO:tensorflow:loss = 0.318578, step = 201 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.281\n",
      "INFO:tensorflow:loss = 0.305172, step = 301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.992\n",
      "INFO:tensorflow:loss = 0.297199, step = 401 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.754\n",
      "INFO:tensorflow:loss = 0.286751, step = 501 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.124\n",
      "INFO:tensorflow:loss = 0.283205, step = 601 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.785\n",
      "INFO:tensorflow:loss = 0.271474, step = 701 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.539\n",
      "INFO:tensorflow:loss = 0.272326, step = 801 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.893\n",
      "INFO:tensorflow:loss = 0.279993, step = 901 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.293\n",
      "INFO:tensorflow:loss = 0.27618, step = 1001 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.864\n",
      "INFO:tensorflow:loss = 0.265082, step = 1101 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.008\n",
      "INFO:tensorflow:loss = 0.265822, step = 1201 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.086\n",
      "INFO:tensorflow:loss = 0.273626, step = 1301 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.257\n",
      "INFO:tensorflow:loss = 0.262035, step = 1401 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.449\n",
      "INFO:tensorflow:loss = 0.268111, step = 1501 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.526\n",
      "INFO:tensorflow:loss = 0.263749, step = 1601 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.043\n",
      "INFO:tensorflow:loss = 0.270492, step = 1701 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.104\n",
      "INFO:tensorflow:loss = 0.261737, step = 1801 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.348\n",
      "INFO:tensorflow:loss = 0.263785, step = 1901 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.759\n",
      "INFO:tensorflow:loss = 0.260046, step = 2001 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.521\n",
      "INFO:tensorflow:loss = 0.258105, step = 2101 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.971\n",
      "INFO:tensorflow:loss = 0.259634, step = 2201 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.804\n",
      "INFO:tensorflow:loss = 0.254835, step = 2301 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.754\n",
      "INFO:tensorflow:loss = 0.2584, step = 2401 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.602\n",
      "INFO:tensorflow:loss = 0.260653, step = 2501 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.746\n",
      "INFO:tensorflow:loss = 0.259094, step = 2601 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.386\n",
      "INFO:tensorflow:loss = 0.253975, step = 2701 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.255\n",
      "INFO:tensorflow:loss = 0.258475, step = 2801 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.968\n",
      "INFO:tensorflow:loss = 0.257237, step = 2901 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.874\n",
      "INFO:tensorflow:loss = 0.245111, step = 3001 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.117\n",
      "INFO:tensorflow:loss = 0.249199, step = 3101 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.812\n",
      "INFO:tensorflow:loss = 0.249544, step = 3201 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.674\n",
      "INFO:tensorflow:loss = 0.253973, step = 3301 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.588\n",
      "INFO:tensorflow:loss = 0.249759, step = 3401 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.031\n",
      "INFO:tensorflow:loss = 0.257461, step = 3501 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.421\n",
      "INFO:tensorflow:loss = 0.255633, step = 3601 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.78\n",
      "INFO:tensorflow:loss = 0.269536, step = 3701 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.46\n",
      "INFO:tensorflow:loss = 0.257968, step = 3801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.01\n",
      "INFO:tensorflow:loss = 0.252102, step = 3901 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.493\n",
      "INFO:tensorflow:loss = 0.248596, step = 4001 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.658\n",
      "INFO:tensorflow:loss = 0.251713, step = 4101 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.227\n",
      "INFO:tensorflow:loss = 0.249645, step = 4201 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.153\n",
      "INFO:tensorflow:loss = 0.248129, step = 4301 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.524\n",
      "INFO:tensorflow:loss = 0.255571, step = 4401 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.073\n",
      "INFO:tensorflow:loss = 0.254273, step = 4501 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.489\n",
      "INFO:tensorflow:loss = 0.254645, step = 4601 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.802\n",
      "INFO:tensorflow:loss = 0.25405, step = 4701 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.368\n",
      "INFO:tensorflow:loss = 0.251647, step = 4801 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.536\n",
      "INFO:tensorflow:loss = 0.241671, step = 4901 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.678\n",
      "INFO:tensorflow:loss = 0.252618, step = 5001 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.967\n",
      "INFO:tensorflow:loss = 0.248812, step = 5101 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.095\n",
      "INFO:tensorflow:loss = 0.246787, step = 5201 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.158\n",
      "INFO:tensorflow:loss = 0.25089, step = 5301 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.361\n",
      "INFO:tensorflow:loss = 0.249165, step = 5401 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.39\n",
      "INFO:tensorflow:loss = 0.242969, step = 5501 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.565\n",
      "INFO:tensorflow:loss = 0.265291, step = 5601 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.573\n",
      "INFO:tensorflow:loss = 0.264722, step = 5701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.986\n",
      "INFO:tensorflow:loss = 0.252699, step = 5801 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.166\n",
      "INFO:tensorflow:loss = 0.246581, step = 5901 (0.237 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.245414.\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-6000\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# 업로드 코드\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "        \n",
    "def _titanic_data_input_fn(data):        \n",
    "    targets = tf.contrib.learn.extract_pandas_data(data.iloc[:,[0]])\n",
    "    feature = tf.contrib.learn.extract_pandas_data(data.drop(['Survived'], axis =1))\n",
    "    return tf.constant(feature), tf.constant(targets)\n",
    "\n",
    "def _predct_data(data):\n",
    "    feature = tf.contrib.learn.extract_pandas_data(data.drop(['PassengerId'], axis =1))\n",
    "    return tf.constant(feature)\n",
    "\n",
    "def DNN(trainData, testData):\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=10)]\n",
    "\n",
    "  # Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                              hidden_units=[64, 32],\n",
    "                                              n_classes=2,\n",
    "                                              optimizer=tf.train.AdamOptimizer(\n",
    "                                                  learning_rate=0.01   \n",
    "                                              ),\n",
    "                                              dropout=0.1,\n",
    "                                              model_dir=\"./dnn_model\")\n",
    "    \n",
    "    \n",
    "    classifier.fit(input_fn=lambda: _titanic_data_input_fn(trainData), steps=6000)\n",
    "    result = list(classifier.predict_classes(input_fn=lambda: _predct_data(testData)))\n",
    "\n",
    "    print(result)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "        \n",
    "result = DNN(train, test)\n",
    "\n",
    "test[\"Survived\"] = result\n",
    "test[[\"PassengerId\", \"Survived\"]].to_csv(\"./result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
